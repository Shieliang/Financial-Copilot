import streamlit as st
import os
import boto3
import tempfile
from langchain_aws import ChatBedrock
from langchain_core.prompts import PromptTemplate
from langchain_community.document_loaders import PyPDFLoader, TextLoader

# ================= ğŸ” å¯†é’¥é…ç½®åŒº =================
os.environ["AWS_ACCESS_KEY_ID"] = "YOUR_AWS_ACCESS_KEY"
os.environ["AWS_SECRET_ACCESS_KEY"] = "YOUR_AWS_SECRET_ACCESS_KEY"
os.environ["AWS_DEFAULT_REGION"] = "us-east-1"

# ================= âš™ï¸ é¡µé¢é…ç½® =================
st.set_page_config(page_title="AI æŠ•èµ„åˆ†æå¸ˆ (Stable Long-Context)", page_icon="ğŸ“ˆ", layout="wide")

model_id = "anthropic.claude-3-5-sonnet-20240620-v1:0"

# ================= ğŸ› ï¸ æ ¸å¿ƒåŠŸèƒ½å‡½æ•° =================

@st.cache_resource
def get_llm():
    """åˆå§‹åŒ– AWS Bedrock LLM"""
    boto3_session = boto3.Session()
    bedrock_client = boto3_session.client(service_name="bedrock-runtime")
    return ChatBedrock(
        model_id=model_id,
        client=bedrock_client,
        model_kwargs={"temperature": 0.0, "max_tokens": 4096} # é™ä½éšæœºæ€§
    )

def extract_full_text(uploaded_files):
    """è¯»å–æ‰€æœ‰ä¸Šä¼ æ–‡ä»¶çš„å®Œæ•´æ–‡æœ¬ï¼Œä¸åˆ‡ç‰‡ï¼Œä¿æŒå…¨æ–‡é€»è¾‘"""
    combined_text = ""
    with tempfile.TemporaryDirectory() as temp_dir:
        for file in uploaded_files:
            file_path = os.path.join(temp_dir, file.name)
            with open(file_path, "wb") as f:
                f.write(file.getbuffer())
            
            # åŠ è½½å…¨æ–‡
            if file.name.lower().endswith('.pdf'):
                loader = PyPDFLoader(file_path)
            else:
                loader = TextLoader(file_path, encoding='utf-8')
            
            docs = loader.load()
            content = "\n".join([doc.page_content for doc in docs])
            combined_text += f"\n\n--- Start of Document: {file.name} ---\n{content}\n--- End of Document ---\n"
    return combined_text

# ================= ğŸ§  è‹±æ–‡é€»è¾‘æ ¸å¿ƒ Prompt =================
# å¼ºåˆ¶ AI åœ¨å†…éƒ¨ä½¿ç”¨è‹±æ–‡æ€è€ƒï¼Œè¾“å‡ºä½¿ç”¨ä¸­æ–‡
analyst_template = """
Role: Senior Buy-side Analyst. Focus on Relative Valuation (P/E & PEG).
Reasoning in ENGLISH, Report in CHINESE.

<thought_process>
1. **Metadata**: Identify Company Name and the specific Fiscal Period.
2. **Unit Audit**: Detect if figures are Millions/Thousands.
3. **Data Extraction**: 
   - Current Stock Price: ${market_price}
   - Net Income (TTM or Current Quarter Annualized)
   - Diluted Shares Outstanding
   - Diluted EPS
   - Forward Guidance (Revenue/EPS for next quarter/year)
3. **Valuation Logic (STRICT HIERARCHY)**:
   - **Step A: Calculate Quarterly Forward EPS**
     - Use Guidance if available, otherwise use Current Q EPS. 
   - **Step B: ANNUALIZE the EPS (CRITICAL)**
     - **Forward Annual EPS = Quarterly Forward EPS * 4**
   - **Step C: Calculate Forward P/E**
     - **P/E = ${market_price} / Forward Annual EPS**
   - **Step D: Calculate PEG**
     - **PEG = (Forward P/E) / {growth_rate}**
4. **Rating Logic**: The final rating MUST align with the PEG and P/E analysis. Do NOT let "company leadership" override extreme valuation multiples.
</thought_process>

---
[CONTEXT]: {full_text}

è¯·ç”ŸæˆæŠ•èµ„ç®€æŠ¥ï¼ˆä¸­æ–‡ï¼‰ï¼š

**[å…¬å¸åç§°] (è‚¡ç¥¨ä»£ç ) - [è´¢æŠ¥å­£åº¦/å¹´åº¦] æŠ•èµ„åˆ†ææŠ¥å‘Š**

ä¸€ã€ å…³é”®è´¢åŠ¡æŒ‡æ ‡

- **ä¸šç»©æ‘˜è¦**ï¼šè¥æ”¶/åˆ©æ¶¦/EPS çš„æ•°å€¼åŠå˜åŠ¨ã€‚
- **çœ‹æ¶¨/çœ‹è·Œè¦ç‚¹**ï¼šè´¢æŠ¥ä¸­æœ€æ ¸å¿ƒçš„ 2-3 ä¸ªé©±åŠ¨åŠ›ä¸éšå¿§ã€‚
- **ç®¡ç†å±‚ç«‹åœº**ï¼š[çœ‹æ¶¨/ä¸­æ€§/çœ‹è·Œ] â€” ç®€è¿°è¯­æ°”ä¸æŒ‡å¼•ã€‚

äºŒã€ ç›¸å¯¹ä¼°å€¼çŸ©é˜µ (Relative Valuation)
- **å‰ç»å¸‚ç›ˆç‡ (Forward P/E)**ï¼šå±•ç¤ºè®¡ç®—è¿‡ç¨‹ï¼ˆè‚¡ä»· / é¢„æœŸæ¯è‚¡æ”¶ç›Šï¼‰ã€‚
- **PEG æ¯”ç‡**ï¼šå±•ç¤ºè®¡ç®—è¿‡ç¨‹ï¼ˆP/E / {growth_rate}% å¢é•¿ç‡ï¼‰ã€‚
- **è¡Œä¸šå¯¹æ¯”ç®€è¿°**ï¼šç®€è¯„è¯¥ä¼°å€¼åœ¨å½“å‰è¡Œä¸šèƒŒæ™¯ä¸‹å¤„äºä»€ä¹ˆä½ç½®ï¼ˆä½ä¼°/åˆç†/æº¢ä»·ï¼‰ã€‚

ä¸‰ã€ è¯„çº§ & ç†ç”±
- **æœ€ç»ˆè¯„çº§**ï¼š[ä¹°å…¥/æŒæœ‰/å–å‡º]
- **æ ¸å¿ƒé€»è¾‘**ï¼šåŸºäº P/E å’Œ PEG çš„ç»å¯¹æ•°å€¼ã€‚
- **å®¡è®¡ç»“è®º**ï¼šæ˜ç¡®æŒ‡å‡ºå½“å‰è‚¡ä»·æ˜¯â€œä½ä¼°â€ã€â€œåˆç†â€è¿˜æ˜¯â€œä¸¥é‡æ³¡æ²«â€ã€‚
- **é£é™©æç¤º**ï¼šé’ˆå¯¹è¯¥å…¬å¸çš„æ ¸å¿ƒä¸šåŠ¡é£é™©ã€‚
---
[OUTPUT FORMAT RULE]:
1. ä½ å¿…é¡»é¦–å…ˆè¾“å‡º <thought_process> æ ‡ç­¾ã€‚
2. åœ¨æ ‡ç­¾å†…ï¼Œè¯¦ç»†è®°å½•ä½ çš„ Unit Audit, Data Extraction, å’Œ Math Logicã€‚
3. å¿…é¡»ä»¥ </thought_process> ç»“æŸè¯¥éƒ¨åˆ†ã€‚
4. ç´§æ¥ç€è¾“å‡ºä¸­æ–‡æŠ•èµ„æŠ¥å‘Šã€‚
5. ç¦æ­¢åˆå¹¶æˆ–å¿½ç•¥æ ‡ç­¾ï¼Œè¿™æ˜¯ç¨‹åºè§£æçš„å”¯ä¸€æ ‡å‡†ã€‚
"""

# ================= ğŸ–¥ï¸ UI ç•Œé¢é€»è¾‘ =================
st.title("AI Investment Copilot")
st.caption("Claude 3.5 Sonnet")

with st.sidebar:
    st.header("1. ä¼°å€¼å‚æ•°")
    current_price = st.number_input("å½“å‰è‚¡ä»· (USD)", value=190.0)
    growth_rate = st.slider("é¢„æœŸå¢é•¿ç‡ (%)", 0, 100, 50)
    st.divider()
    uploaded_files = st.file_uploader("ä¸Šä¼ è´¢æŠ¥ (PDF/TXT)", type=['pdf', 'txt'], accept_multiple_files=True)
    
    st.divider()
    process_btn = st.button("ğŸš€ å¼€å§‹å…¨æ–‡åˆ†æ", type="primary")
    
    if st.button("ğŸ—‘ï¸ é‡ç½®åˆ†æå¸ˆè®°å¿†"):
        for key in list(st.session_state.keys()): del st.session_state[key]
        st.rerun()

# --- ä¸»ç¨‹åºé€»è¾‘ ---
if process_btn and uploaded_files:
    try:
        llm = get_llm()
        
        with st.spinner("1/2 æ­£åœ¨æå–å…¨æ–‡æ•°æ® (ä¿æŒå‹¾ç¨½å…³ç³»)..."):
            full_context_text = extract_full_text(uploaded_files)
            # å­˜å‚¨å…¨æ–‡ä»¥ä¾¿è¿½é—®
            st.session_state.full_context = full_context_text

        with st.spinner("2/2 AI æ­£åœ¨è¿›è¡Œè‹±æ–‡é€»è¾‘æ¨æ¼”å¹¶ç¿»è¯‘æŠ¥å‘Š..."):
            # ç»„è£… Prompt
            final_prompt = analyst_template.format(
                full_text=full_context_text,
                market_price=current_price,
                growth_rate=growth_rate
            )
            
            # ç›´æ¥è°ƒç”¨ LLMï¼Œä¸å†é€šè¿‡å¤æ‚çš„ Chain
            response = llm.invoke(final_prompt)
            st.session_state.report = response.content

    except Exception as e:
        st.error(f"âŒ åˆ†æå¤±è´¥: {str(e)}")

# --- ç»“æœå±•ç¤º ---
if "report" in st.session_state:
    st.markdown("---")
    
    # å°è¯•åˆ†ç¦» Thought Process (å¦‚æœ AI è¾“å‡ºäº†æ ‡ç­¾)
    raw_output = st.session_state.report
    if "<thought_process>" in raw_output and "</thought_process>" in raw_output:
        thought, report = raw_output.split("</thought_process>")
        with st.expander("ğŸ” æŸ¥çœ‹ AI å†…éƒ¨é€»è¾‘å®¡è®¡"):
            st.write(thought.replace("<thought_process>", "").strip())
        st.markdown(report.strip())
    else:
        st.markdown(raw_output)